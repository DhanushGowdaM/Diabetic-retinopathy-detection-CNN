{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade tensorflow\n",
    "!pip install os\n",
    "!pip install plotly\n",
    "!conda install -c plotly plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9d2224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import display\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8064155f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1057ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images : 3662 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the number of images in the dataset\n",
    "train = []\n",
    "label = []\n",
    "\n",
    "# os.listdir returns the list of files in the folder, in this case image class names\n",
    "for i in os.listdir('./train'):\n",
    "  train_class = os.listdir(os.path.join('train', i))\n",
    "  for j in train_class:\n",
    "    img = os.path.join('train', i, j)\n",
    "    train.append(img)\n",
    "    label.append(i)\n",
    "\n",
    "print('Number of train images : {} \\n'.format(len(train)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f78cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in Mild = 370 \n",
      "\n",
      "Number of images in Moderate = 999 \n",
      "\n",
      "Number of images in No_DR = 1805 \n",
      "\n",
      "Number of images in Proliferate_DR = 295 \n",
      "\n",
      "Number of images in Severe = 193 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the number of images in each class in the training dataset\n",
    "\n",
    "No_images_per_class = []\n",
    "Class_name = []\n",
    "for i in os.listdir('./train'):\n",
    "  train_class = os.listdir(os.path.join('train', i))\n",
    "  No_images_per_class.append(len(train_class))\n",
    "  Class_name.append(i)\n",
    "  print('Number of images in {} = {} \\n'.format(i, len(train_class)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd699b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train\\Mild\\0024cdab0c1e.png</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train\\Mild\\00cb6555d108.png</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train\\Mild\\0124dffecf29.png</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train\\Mild\\01b3aed3ed4c.png</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train\\Mild\\0369f3efe69b.png</td>\n",
       "      <td>Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>train\\Severe\\f9156aeffc5e.png</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>train\\Severe\\fb61230b99dd.png</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>train\\Severe\\fcc6aa6755e6.png</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>train\\Severe\\fda39982a810.png</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>train\\Severe\\fe0fc67c7980.png</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3662 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Image  Labels\n",
       "0       train\\Mild\\0024cdab0c1e.png    Mild\n",
       "1       train\\Mild\\00cb6555d108.png    Mild\n",
       "2       train\\Mild\\0124dffecf29.png    Mild\n",
       "3       train\\Mild\\01b3aed3ed4c.png    Mild\n",
       "4       train\\Mild\\0369f3efe69b.png    Mild\n",
       "...                             ...     ...\n",
       "3657  train\\Severe\\f9156aeffc5e.png  Severe\n",
       "3658  train\\Severe\\fb61230b99dd.png  Severe\n",
       "3659  train\\Severe\\fcc6aa6755e6.png  Severe\n",
       "3660  train\\Severe\\fda39982a810.png  Severe\n",
       "3661  train\\Severe\\fe0fc67c7980.png  Severe\n",
       "\n",
       "[3662 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retina_df = pd.DataFrame({'Image': train,'Labels': label})\n",
    "retina_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7943b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2490 validated image filenames belonging to 5 classes.\n",
      "Found 439 validated image filenames belonging to 5 classes.\n",
      "Found 733 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data and split it into training and testing\n",
    "retina_df = shuffle(retina_df)\n",
    "train, test = train_test_split(retina_df, test_size = 0.2)\n",
    "\n",
    "# Create run-time augmentation on training and test dataset\n",
    "# For training datagenerator, we add normalization, shear angle, zooming range and horizontal flip\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        validation_split = 0.15)\n",
    "\n",
    "# For test datagenerator, we only normalize the data.\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Creating datagenerator for training, validation and test dataset.\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    train,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test,\n",
    "    directory='./',\n",
    "    x_col=\"Image\",\n",
    "    y_col=\"Labels\",\n",
    "    target_size=(256, 256),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    "    batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75e08bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Resnet18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (None, 262, 262, 3)          0         ['input_2[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv1 (Conv2D)              (None, 128, 128, 64)         9472      ['zero_padding2d_1[0][0]']    \n",
      "                                                                                                  \n",
      " bn_conv1 (BatchNormalizati  (None, 128, 128, 64)         256       ['conv1[0][0]']               \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)  (None, 128, 128, 64)         0         ['bn_conv1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 63, 63, 64)           0         ['activation_28[0][0]']       \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " res_2_conv_a (Conv2D)       (None, 63, 63, 64)           4160      ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 31, 31, 64)           0         ['res_2_conv_a[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " bn_2_conv_a (BatchNormaliz  (None, 31, 31, 64)           256       ['max_pooling2d_8[0][0]']     \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_29 (Activation)  (None, 31, 31, 64)           0         ['bn_2_conv_a[0][0]']         \n",
      "                                                                                                  \n",
      " res_2_conv_b (Conv2D)       (None, 31, 31, 64)           36928     ['activation_29[0][0]']       \n",
      "                                                                                                  \n",
      " bn_2_conv_b (BatchNormaliz  (None, 31, 31, 64)           256       ['res_2_conv_b[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_30 (Activation)  (None, 31, 31, 64)           0         ['bn_2_conv_b[0][0]']         \n",
      "                                                                                                  \n",
      " res_2_conv_copy (Conv2D)    (None, 63, 63, 256)          16640     ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " res_2_conv_c (Conv2D)       (None, 31, 31, 256)          16640     ['activation_30[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 31, 31, 256)          0         ['res_2_conv_copy[0][0]']     \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " bn_2_conv_c (BatchNormaliz  (None, 31, 31, 256)          1024      ['res_2_conv_c[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_2_conv_copy (BatchNorma  (None, 31, 31, 256)          1024      ['max_pooling2d_9[0][0]']     \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 31, 31, 256)          0         ['bn_2_conv_c[0][0]',         \n",
      "                                                                     'bn_2_conv_copy[0][0]']      \n",
      "                                                                                                  \n",
      " activation_31 (Activation)  (None, 31, 31, 256)          0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " res_2_identity_1_a (Conv2D  (None, 31, 31, 64)           16448     ['activation_31[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_2_identity_1_a (BatchNo  (None, 31, 31, 64)           256       ['res_2_identity_1_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_32 (Activation)  (None, 31, 31, 64)           0         ['bn_2_identity_1_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_2_identity_1_b (Conv2D  (None, 31, 31, 64)           36928     ['activation_32[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_2_identity_1_b (BatchNo  (None, 31, 31, 64)           256       ['res_2_identity_1_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_33 (Activation)  (None, 31, 31, 64)           0         ['bn_2_identity_1_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_2_identity_1_c (Conv2D  (None, 31, 31, 256)          16640     ['activation_33[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_2_identity_1_c (BatchNo  (None, 31, 31, 256)          1024      ['res_2_identity_1_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 31, 31, 256)          0         ['bn_2_identity_1_c[0][0]',   \n",
      "                                                                     'activation_31[0][0]']       \n",
      "                                                                                                  \n",
      " activation_34 (Activation)  (None, 31, 31, 256)          0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " res_2_identity_2_a (Conv2D  (None, 31, 31, 64)           16448     ['activation_34[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bn_2_identity_2_a (BatchNo  (None, 31, 31, 64)           256       ['res_2_identity_2_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_35 (Activation)  (None, 31, 31, 64)           0         ['bn_2_identity_2_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_2_identity_2_b (Conv2D  (None, 31, 31, 64)           36928     ['activation_35[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_2_identity_2_b (BatchNo  (None, 31, 31, 64)           256       ['res_2_identity_2_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_36 (Activation)  (None, 31, 31, 64)           0         ['bn_2_identity_2_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_2_identity_2_c (Conv2D  (None, 31, 31, 256)          16640     ['activation_36[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_2_identity_2_c (BatchNo  (None, 31, 31, 256)          1024      ['res_2_identity_2_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 31, 31, 256)          0         ['bn_2_identity_2_c[0][0]',   \n",
      "                                                                     'activation_34[0][0]']       \n",
      "                                                                                                  \n",
      " activation_37 (Activation)  (None, 31, 31, 256)          0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " res_3_conv_a (Conv2D)       (None, 31, 31, 128)          32896     ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 15, 15, 128)          0         ['res_3_conv_a[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " bn_3_conv_a (BatchNormaliz  (None, 15, 15, 128)          512       ['max_pooling2d_10[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_38 (Activation)  (None, 15, 15, 128)          0         ['bn_3_conv_a[0][0]']         \n",
      "                                                                                                  \n",
      " res_3_conv_b (Conv2D)       (None, 15, 15, 128)          147584    ['activation_38[0][0]']       \n",
      "                                                                                                  \n",
      " bn_3_conv_b (BatchNormaliz  (None, 15, 15, 128)          512       ['res_3_conv_b[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_39 (Activation)  (None, 15, 15, 128)          0         ['bn_3_conv_b[0][0]']         \n",
      "                                                                                                  \n",
      " res_3_conv_copy (Conv2D)    (None, 31, 31, 512)          131584    ['activation_37[0][0]']       \n",
      "                                                                                                  \n",
      " res_3_conv_c (Conv2D)       (None, 15, 15, 512)          66048     ['activation_39[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 15, 15, 512)          0         ['res_3_conv_copy[0][0]']     \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " bn_3_conv_c (BatchNormaliz  (None, 15, 15, 512)          2048      ['res_3_conv_c[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_3_conv_copy (BatchNorma  (None, 15, 15, 512)          2048      ['max_pooling2d_11[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 15, 15, 512)          0         ['bn_3_conv_c[0][0]',         \n",
      "                                                                     'bn_3_conv_copy[0][0]']      \n",
      "                                                                                                  \n",
      " activation_40 (Activation)  (None, 15, 15, 512)          0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " res_3_identity_1_a (Conv2D  (None, 15, 15, 128)          65664     ['activation_40[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_1_a (BatchNo  (None, 15, 15, 128)          512       ['res_3_identity_1_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_41 (Activation)  (None, 15, 15, 128)          0         ['bn_3_identity_1_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_3_identity_1_b (Conv2D  (None, 15, 15, 128)          147584    ['activation_41[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_1_b (BatchNo  (None, 15, 15, 128)          512       ['res_3_identity_1_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_42 (Activation)  (None, 15, 15, 128)          0         ['bn_3_identity_1_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_3_identity_1_c (Conv2D  (None, 15, 15, 512)          66048     ['activation_42[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_1_c (BatchNo  (None, 15, 15, 512)          2048      ['res_3_identity_1_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 15, 15, 512)          0         ['bn_3_identity_1_c[0][0]',   \n",
      "                                                                     'activation_40[0][0]']       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_43 (Activation)  (None, 15, 15, 512)          0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " res_3_identity_2_a (Conv2D  (None, 15, 15, 128)          65664     ['activation_43[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_2_a (BatchNo  (None, 15, 15, 128)          512       ['res_3_identity_2_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_44 (Activation)  (None, 15, 15, 128)          0         ['bn_3_identity_2_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_3_identity_2_b (Conv2D  (None, 15, 15, 128)          147584    ['activation_44[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_2_b (BatchNo  (None, 15, 15, 128)          512       ['res_3_identity_2_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_45 (Activation)  (None, 15, 15, 128)          0         ['bn_3_identity_2_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_3_identity_2_c (Conv2D  (None, 15, 15, 512)          66048     ['activation_45[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_3_identity_2_c (BatchNo  (None, 15, 15, 512)          2048      ['res_3_identity_2_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_14 (Add)                (None, 15, 15, 512)          0         ['bn_3_identity_2_c[0][0]',   \n",
      "                                                                     'activation_43[0][0]']       \n",
      "                                                                                                  \n",
      " activation_46 (Activation)  (None, 15, 15, 512)          0         ['add_14[0][0]']              \n",
      "                                                                                                  \n",
      " res_4_conv_a (Conv2D)       (None, 15, 15, 256)          131328    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooli  (None, 7, 7, 256)            0         ['res_4_conv_a[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " bn_4_conv_a (BatchNormaliz  (None, 7, 7, 256)            1024      ['max_pooling2d_12[0][0]']    \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_47 (Activation)  (None, 7, 7, 256)            0         ['bn_4_conv_a[0][0]']         \n",
      "                                                                                                  \n",
      " res_4_conv_b (Conv2D)       (None, 7, 7, 256)            590080    ['activation_47[0][0]']       \n",
      "                                                                                                  \n",
      " bn_4_conv_b (BatchNormaliz  (None, 7, 7, 256)            1024      ['res_4_conv_b[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " activation_48 (Activation)  (None, 7, 7, 256)            0         ['bn_4_conv_b[0][0]']         \n",
      "                                                                                                  \n",
      " res_4_conv_copy (Conv2D)    (None, 15, 15, 1024)         525312    ['activation_46[0][0]']       \n",
      "                                                                                                  \n",
      " res_4_conv_c (Conv2D)       (None, 7, 7, 1024)           263168    ['activation_48[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooli  (None, 7, 7, 1024)           0         ['res_4_conv_copy[0][0]']     \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " bn_4_conv_c (BatchNormaliz  (None, 7, 7, 1024)           4096      ['res_4_conv_c[0][0]']        \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " bn_4_conv_copy (BatchNorma  (None, 7, 7, 1024)           4096      ['max_pooling2d_13[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " add_15 (Add)                (None, 7, 7, 1024)           0         ['bn_4_conv_c[0][0]',         \n",
      "                                                                     'bn_4_conv_copy[0][0]']      \n",
      "                                                                                                  \n",
      " activation_49 (Activation)  (None, 7, 7, 1024)           0         ['add_15[0][0]']              \n",
      "                                                                                                  \n",
      " res_4_identity_1_a (Conv2D  (None, 7, 7, 256)            262400    ['activation_49[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_4_identity_1_a (BatchNo  (None, 7, 7, 256)            1024      ['res_4_identity_1_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_50 (Activation)  (None, 7, 7, 256)            0         ['bn_4_identity_1_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_4_identity_1_b (Conv2D  (None, 7, 7, 256)            590080    ['activation_50[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_4_identity_1_b (BatchNo  (None, 7, 7, 256)            1024      ['res_4_identity_1_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_51 (Activation)  (None, 7, 7, 256)            0         ['bn_4_identity_1_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_4_identity_1_c (Conv2D  (None, 7, 7, 1024)           263168    ['activation_51[0][0]']       \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " bn_4_identity_1_c (BatchNo  (None, 7, 7, 1024)           4096      ['res_4_identity_1_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_16 (Add)                (None, 7, 7, 1024)           0         ['bn_4_identity_1_c[0][0]',   \n",
      "                                                                     'activation_49[0][0]']       \n",
      "                                                                                                  \n",
      " activation_52 (Activation)  (None, 7, 7, 1024)           0         ['add_16[0][0]']              \n",
      "                                                                                                  \n",
      " res_4_identity_2_a (Conv2D  (None, 7, 7, 256)            262400    ['activation_52[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_4_identity_2_a (BatchNo  (None, 7, 7, 256)            1024      ['res_4_identity_2_a[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_53 (Activation)  (None, 7, 7, 256)            0         ['bn_4_identity_2_a[0][0]']   \n",
      "                                                                                                  \n",
      " res_4_identity_2_b (Conv2D  (None, 7, 7, 256)            590080    ['activation_53[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_4_identity_2_b (BatchNo  (None, 7, 7, 256)            1024      ['res_4_identity_2_b[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_54 (Activation)  (None, 7, 7, 256)            0         ['bn_4_identity_2_b[0][0]']   \n",
      "                                                                                                  \n",
      " res_4_identity_2_c (Conv2D  (None, 7, 7, 1024)           263168    ['activation_54[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bn_4_identity_2_c (BatchNo  (None, 7, 7, 1024)           4096      ['res_4_identity_2_c[0][0]']  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_17 (Add)                (None, 7, 7, 1024)           0         ['bn_4_identity_2_c[0][0]',   \n",
      "                                                                     'activation_52[0][0]']       \n",
      "                                                                                                  \n",
      " activation_55 (Activation)  (None, 7, 7, 1024)           0         ['add_17[0][0]']              \n",
      "                                                                                                  \n",
      " Averagea_Pooling (AverageP  (None, 3, 3, 1024)           0         ['activation_55[0][0]']       \n",
      " ooling2D)                                                                                        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 9216)                 0         ['Averagea_Pooling[0][0]']    \n",
      "                                                                                                  \n",
      " Dense_final (Dense)         (None, 5)                    46085     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4987525 (19.03 MB)\n",
      "Trainable params: 4967685 (18.95 MB)\n",
      "Non-trainable params: 19840 (77.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def res_block(X, filter, stage):\n",
    "  \n",
    "  # Convolutional_block\n",
    "  X_copy = X\n",
    "\n",
    "  f1 , f2, f3 = filter\n",
    "    \n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_conv_a', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = MaxPool2D((2,2))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_conv_b', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_c', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_c')(X)\n",
    "\n",
    "\n",
    "  # Short path\n",
    "  X_copy = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_conv_copy', \n",
    "                  kernel_initializer= glorot_uniform(seed = 0))(X_copy)\n",
    "  X_copy = MaxPool2D((2,2))(X_copy)\n",
    "  X_copy = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_conv_copy')(X_copy)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 1\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_1_a', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_1_b', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_1_c', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_1_c')(X)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  # Identity Block 2\n",
    "  X_copy = X\n",
    "\n",
    "\n",
    "  # Main Path\n",
    "  X = Conv2D(f1, (1,1),strides = (1,1), name ='res_'+str(stage)+'_identity_2_a', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_a')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f2, kernel_size = (3,3), strides =(1,1), padding = 'same', name ='res_'+str(stage)+'_identity_2_b', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_b')(X)\n",
    "  X = Activation('relu')(X) \n",
    "\n",
    "  X = Conv2D(f3, kernel_size = (1,1), strides =(1,1),name ='res_'+str(stage)+'_identity_2_c', \n",
    "             kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "  X = BatchNormalization(axis =3, name = 'bn_'+str(stage)+'_identity_2_c')(X)\n",
    "\n",
    "  # ADD\n",
    "  X = Add()([X,X_copy])\n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  return X\n",
    "\n",
    "\n",
    "input_shape = (256,256,3)\n",
    "\n",
    "#Input tensor shape\n",
    "X_input = Input(input_shape)\n",
    "\n",
    "#Zero-padding\n",
    "\n",
    "X = ZeroPadding2D((3,3))(X_input)\n",
    "\n",
    "# 1 - stage\n",
    "\n",
    "X = Conv2D(64, (7,7), strides= (2,2), name = 'conv1', kernel_initializer= glorot_uniform(seed = 0))(X)\n",
    "X = BatchNormalization(axis =3, name = 'bn_conv1')(X)\n",
    "X = Activation('relu')(X)\n",
    "X = MaxPooling2D((3,3), strides= (2,2))(X)\n",
    "\n",
    "# 2- stage\n",
    "\n",
    "X = res_block(X, filter= [64,64,256], stage= 2)\n",
    "\n",
    "# 3- stage\n",
    "\n",
    "X = res_block(X, filter= [128,128,512], stage= 3)\n",
    "\n",
    "# 4- stage\n",
    "\n",
    "X = res_block(X, filter= [256,256,1024], stage= 4)\n",
    "\n",
    "# # 5- stage\n",
    "\n",
    "# X = res_block(X, filter= [512,512,2048], stage= 5)\n",
    "\n",
    "#Average Pooling\n",
    "\n",
    "X = AveragePooling2D((2,2), name = 'Averagea_Pooling')(X)\n",
    "\n",
    "#Final layer\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dense(5, activation = 'softmax', name = 'Dense_final', kernel_initializer= glorot_uniform(seed=0))(X)\n",
    "\n",
    "\n",
    "model = Model( inputs= X_input, outputs = X, name = 'Resnet18')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c890b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics= ['accuracy'])\n",
    "\n",
    "#using early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "\n",
    "#save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f60c609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 1.3640 - accuracy: 0.6444\n",
      "Epoch 1: val_loss improved from inf to 1.81329, saving model to weights.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinod\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning:\n",
      "\n",
      "You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 342s 4s/step - loss: 1.3640 - accuracy: 0.6444 - val_loss: 1.8133 - val_accuracy: 0.2572\n",
      "Epoch 2/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.8676 - accuracy: 0.7091\n",
      "Epoch 2: val_loss improved from 1.81329 to 1.50787, saving model to weights.hdf5\n",
      "77/77 [==============================] - 351s 5s/step - loss: 0.8676 - accuracy: 0.7091 - val_loss: 1.5079 - val_accuracy: 0.2572\n",
      "Epoch 3/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.7970 - accuracy: 0.7103\n",
      "Epoch 3: val_loss did not improve from 1.50787\n",
      "77/77 [==============================] - 361s 5s/step - loss: 0.7970 - accuracy: 0.7103 - val_loss: 1.9013 - val_accuracy: 0.2428\n",
      "Epoch 4/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.7131 - accuracy: 0.7286\n",
      "Epoch 4: val_loss improved from 1.50787 to 1.40044, saving model to weights.hdf5\n",
      "77/77 [==============================] - 323s 4s/step - loss: 0.7131 - accuracy: 0.7286 - val_loss: 1.4004 - val_accuracy: 0.4856\n",
      "Epoch 5/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6621 - accuracy: 0.7498\n",
      "Epoch 5: val_loss improved from 1.40044 to 1.32862, saving model to weights.hdf5\n",
      "77/77 [==============================] - 323s 4s/step - loss: 0.6621 - accuracy: 0.7498 - val_loss: 1.3286 - val_accuracy: 0.3582\n",
      "Epoch 6/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.7632\n",
      "Epoch 6: val_loss did not improve from 1.32862\n",
      "77/77 [==============================] - 336s 4s/step - loss: 0.6343 - accuracy: 0.7632 - val_loss: 1.3916 - val_accuracy: 0.4159\n",
      "Epoch 7/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6473 - accuracy: 0.7600\n",
      "Epoch 7: val_loss improved from 1.32862 to 0.93791, saving model to weights.hdf5\n",
      "77/77 [==============================] - 347s 5s/step - loss: 0.6473 - accuracy: 0.7600 - val_loss: 0.9379 - val_accuracy: 0.6370\n",
      "Epoch 8/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.7616\n",
      "Epoch 8: val_loss improved from 0.93791 to 0.82272, saving model to weights.hdf5\n",
      "77/77 [==============================] - 344s 4s/step - loss: 0.6317 - accuracy: 0.7616 - val_loss: 0.8227 - val_accuracy: 0.6899\n",
      "Epoch 9/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7876\n",
      "Epoch 9: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 339s 4s/step - loss: 0.5492 - accuracy: 0.7876 - val_loss: 1.0766 - val_accuracy: 0.5433\n",
      "Epoch 10/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.8100\n",
      "Epoch 10: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 328s 4s/step - loss: 0.5017 - accuracy: 0.8100 - val_loss: 1.4516 - val_accuracy: 0.5361\n",
      "Epoch 11/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4700 - accuracy: 0.8206\n",
      "Epoch 11: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 343s 4s/step - loss: 0.4700 - accuracy: 0.8206 - val_loss: 1.3474 - val_accuracy: 0.5168\n",
      "Epoch 12/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.8291\n",
      "Epoch 12: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 324s 4s/step - loss: 0.5330 - accuracy: 0.8291 - val_loss: 63.8701 - val_accuracy: 0.4447\n",
      "Epoch 13/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.7653\n",
      "Epoch 13: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 300s 4s/step - loss: 0.6694 - accuracy: 0.7653 - val_loss: 3.5339 - val_accuracy: 0.5192\n",
      "Epoch 14/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.5364 - accuracy: 0.7998\n",
      "Epoch 14: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 304s 4s/step - loss: 0.5364 - accuracy: 0.7998 - val_loss: 2.3061 - val_accuracy: 0.5120\n",
      "Epoch 15/15\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8356\n",
      "Epoch 15: val_loss did not improve from 0.82272\n",
      "77/77 [==============================] - 308s 4s/step - loss: 0.4316 - accuracy: 0.8356 - val_loss: 1.0974 - val_accuracy: 0.5793\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch = train_generator.n // 32, epochs = 15, \n",
    "                    validation_data= validation_generator, validation_steps= validation_generator.n // 32, \n",
    "                    callbacks=[checkpointer , earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcbe5303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 35s 2s/step - loss: 0.8741 - accuracy: 0.6648\n",
      "Accuracy Test : 0.6647727489471436\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"weights.hdf5\")\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "evaluate = model.evaluate(test_generator, steps = test_generator.n // 32, verbose =1)\n",
    "\n",
    "print('Accuracy Test : {}'.format(evaluate[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd67ad3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5df1aaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning label names to the corresponding indexes\n",
    "labels = {0: 'Mild', 1: 'Moderate', 2: 'No_DR', 3:'Proliferate_DR', 4: 'Severe'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba5931a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "# Loading images and their predictions \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import cv2\n",
    "\n",
    "prediction = []\n",
    "original = []\n",
    "image = []\n",
    "count = 0\n",
    "\n",
    "for item in range(len(test)):\n",
    "  #code to open the image\n",
    "  img= PIL.Image.open(test['Image'].tolist()[item])\n",
    "  #resizing the image to (256,256)\n",
    "  img = img.resize((256,256))\n",
    "  #appending image to the image list\n",
    "  image.append(img)\n",
    "  #converting image to array\n",
    "  img = np.asarray(img, dtype= np.float32)\n",
    "  #normalizing the image\n",
    "  img = img / 255\n",
    "  #reshaping the image in to a 4D array\n",
    "  img = img.reshape(-1,256,256,3)\n",
    "  #making prediction of the model\n",
    "  predict = model.predict(img)\n",
    "  #getting the index corresponding to the highest value in the prediction\n",
    "  predict = np.argmax(predict)\n",
    "  #appending the predicted class to the list\n",
    "  prediction.append(labels[predict])\n",
    "  #appending original class to the list\n",
    "  original.append(test['Labels'].tolist()[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47062a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
